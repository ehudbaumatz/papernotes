# papernotes

## sequence to sequence 
* A Neural Attention Model for Abstractive Summarization. ([Arxiv](https://arxiv.org/pdf/1509.00685v2.pdf))
* Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond ([Arxiv](http://arxiv.org/pdf/1602.06023v2.pdf))
 
## Residual Networks
* Swapout: Learning an ensemble of deep architectures([Arxiv](http://arxiv.org/abs/1605.06465v1))
 


